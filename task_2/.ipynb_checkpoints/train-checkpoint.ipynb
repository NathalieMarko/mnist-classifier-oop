{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2025f6f-0ed8-4a2a-812b-18686a1803e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0393, Train Acc: 0.6580, Val Acc: 0.7514\n",
      "Epoch [2/5], Loss: 0.7130, Train Acc: 0.7647, Val Acc: 0.8276\n",
      "Epoch [3/5], Loss: 0.5973, Train Acc: 0.8031, Val Acc: 0.8251\n",
      "Epoch [4/5], Loss: 0.5055, Train Acc: 0.8332, Val Acc: 0.8542\n",
      "Epoch [5/5], Loss: 0.4603, Train Acc: 0.8489, Val Acc: 0.8446\n",
      "Training complete. Best val accuracy: 0.8541945346837378\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import split_data\n",
    "\n",
    "def train_image_classifier(\n",
    "    data_dir='/Users/nataliamarko/Documents/GitHub/mnist-classifier-oop/task_2/data/',\n",
    "    output_dir=\"./models/image_classifier\",\n",
    "    num_classes=10,\n",
    "    batch_size=64,\n",
    "    epochs=4,\n",
    "    learning_rate=1e-3,\n",
    "    val_ratio=0.3\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a ResNet50 to classify 10 animal classes with resized images and enhanced data augmentation.\n",
    "    \"\"\"\n",
    "    base_directory = '/Users/nataliamarko/Documents/GitHub/mnist-classifier-oop/task_2/'\n",
    "    train_dir = os.path.join(base_directory, 'train')\n",
    "    val_dir = os.path.join(base_directory, 'val')\n",
    "\n",
    "    if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n",
    "        print(\"Splitting dataset into train/val sets...\")\n",
    "        split_data.split_dataset(source_dir=data_dir, base_dir=base_directory, val_ratio=val_ratio)\n",
    "\n",
    "    # Enhanced train_transform with AutoAugment\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(policy=torchvision.transforms.AutoAugmentPolicy.IMAGENET),  # AutoAugment with IMAGENET policy\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "    val_dataset = ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct, total_samples = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_correct += torch.sum(preds == labels).item()\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "        avg_train_loss = total_loss / total_samples\n",
    "        train_acc = total_correct / total_samples\n",
    "\n",
    "        model.eval()\n",
    "        val_correct, val_samples = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels).item()\n",
    "                val_samples += images.size(0)\n",
    "        val_acc = val_correct / val_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, \"best_model.pth\"))\n",
    "\n",
    "    print(\"Training complete. Best val accuracy:\", best_val_acc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_image_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55f528-37e1-4258-bd30-d1878390b9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
